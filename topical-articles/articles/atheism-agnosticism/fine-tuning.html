<!doctype html>
<html lang="en">

<head>
    <title>Some Reliable Fine Tuning of the Universe Citations | FaithAlone.net</title>
    <meta name="description" content="Citations describing the fine-tuning of the universe">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <!-- https://faithalone.net/topical-articles/articles/ -->
    <link rel="canonical" href="https://faithalone.net/topical-articles/articles/atheism-agnosticism/fine-tuning.html"/>

    <!-- Bootstrap CSS, my custom CSS -->
    <link rel="stylesheet" href="../../../style/bootstrap/css/bootstrap.min.css">
    <link rel="stylesheet" href="../../../style/style.css">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-99T7NZDVND"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());
        gtag('config', 'G-99T7NZDVND');
    </script>
</head>

<body>
    <header>
        <div class="container-fluid py-2">
            <h1 class= "mb-0 title" style="font-family: Cinzel Decorative;">
                <a href="../../../index.html">FaithAlone.net</a>
            </h1>
        </div>
    </header>

    <nav class="navbar navbar-expand-md navbar-dark bg-dark sticky-top">
        <div class="container-fluid">

            <button class="navbar-toggler" style="color:white;" data-bs-toggle="collapse" data-bs-target="#collapse_target">
                <span class="navbar-toggler-icon"></span>&nbsp Menu
            </button>

            <div class="collapse navbar-collapse" id="collapse_target">
                <ul class="navbar-nav mr-auto">
                    <li class="nav-item">
                        <a class="nav-link" href="../../../index.html">Home</a>
                    </li>
                    <li class="nav-item active">
                        <a class="nav-link" href="../../../topical-articles/topical-articles.html">Topical Articles</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="../../../about-contact/about-contact.html">About & Contact</a>
                    </li>
                </ul>
            </div>
        </div>
    </nav>

    <!--- TITLE -->
    <div class="container fluid pt-4 pb-2">
        <div class="row">
            <div class="col-12 article-background rounded py-3">
                <h1 style="text-align: center;">Some Reliable Fine Tuning of the Universe Citations</h1>
            </div>
        </div>
    </div>

    <div class="container fluid py-3">
        <div class="row justify-content-center">
            <div class="col-12 article-background rounded pt-2 px-4">

                <!-- ARTICLE -->
                <div class="row justify-content-center">
                    <div class="col-lg-11 col-sm-12 py-4">
                        <!-- Some Christian fine-tuning articles exemplifying the issue: 
                            https://evolutionnews.org/2017/11/ids-top-six-the-fine-tuning-of-the-universe/ 
                            https://www.discovery.org/v/the-fine-tuning-of-the-universe/
                        -->
                        <!-- Some responses to fine-tuning "debunks"
                            - https://mathscholar.org/2018/03/has-cosmic-fine-tuning-been-refuted/
                            - https://www.michaelgstrauss.com/2017/07/is-fine-tuning-fallacy.html 
                            - https://letterstonature.wordpress.com/2012/05/02/in-defence-of-the-fine-tuning-of-the-universe-for-intelligent-life/ 
                            - https://letterstonature.wordpress.com/2020/07/25/a-thick-layer-a-fine-tuned-critique-of-arvin-ash/
                            - https://web.archive.org/web/20220121042642/http://home.messiah.edu/~rcollins/Fine-tuning/Stenger-fallacy.pdf 
                            

                            Even if it could be proven that all of these forces are contingent (derived), and interrelated, that still would not solve the problem, because that would need an explanation as well. That just moves the problem one level of abstraction higher.

                            From page 275 of The Blackwell Companion to Natural Theology, on there being a "more fundamental law" which explains all the apparent fine-tuning we see in nature:
                                Hypothesizing such a law merely moves the epistemic improbability of the fine-tuning of the laws and constants up one level, to that of the postulated fundamental law itself. Even if such a law existed, it would still be a huge coincidence that the fundamental law implied just those lower-level laws and values of the constants of physics that are life-permitting, instead of some other laws or values. As astrophysicists Bernard Carr and Martin Rees note, "even if all apparently anthropic coincidences could be explained [in terms of some fundamental law], it would still be remarkable that the relationships dictated by physical theory happened also to be those propitious for life" (1979, p. 612). It is very unlikely, therefore, that the fine-tuning of the universe would lose its significance even if such a law were verified.
                        -->
                        <!-- Other thoughts
                            Martin Rees in https://youtu.be/E0zdXj6fSGY?si=G5NcwERHY6JYksiA - only 2 dimensions would preclude a complex universe
                        -->
                        <!-- Remove '' - -->
                        <p class="article-body">
                            Many people, when giving the Teleological Argument, will cite fine-tuning parameters for universal constants - i.e., <i>if force x were modified by one part in 10<sup>20</sup>, life would be impossible. </i>
                        </p>
                        <p class="article-body">
                            However, they often neglect to cite <i>where</i> they got these numbers from, even in footnotes. This article will attempt to remedy this, by quoting original sources, written by qualified experts in their field, detailing the fine-tuning of the universe.
                        </p>
                        <p class="article-body">
                            Also see <a href="#appendix-I">Appendix I</a> for brief responses to common Atheist rebuttals to the universe's fine-tuning.
                        </p>
                        <h3>Citations</h3>
                        <h4>Stephen Hawking</h4>
                        <ul style="font-size:large">
                            <li>Stephen Hawking earned a PhD in physics from the University of Cambridge, and taught at Cambridge for 30 years</li>
                        </ul>
                        <blockquote>
                            <h5 class="pt-2">Stephen Hawking - A Brief History of Time, Chapter 8</h5>
                            <p class="mb-1">
                                Why did the universe start out with so nearly the critical rate of expansion that separates models that recollapse from those that go on expanding forever, that even now, ten thousand million years later, it is still expanding at nearly the critical rate? <b>If the rate of expansion one second after the big bang had been smaller by even one part in a hundred thousand million million, the universe would have recollapsed before it ever reached its present size.</b>
                            </p>
                        </blockquote>
                        <h4 class="pt-2">Martin Rees</h4>
                        <ul style="font-size:large">
                            <li>Martin Rees earned a PhD in astronomy from the University of Cambridge, and served as a professor at Cambridge</li>
                        </ul>
                        <blockquote>
                            <h5 class="pt-2">Martin Rees - Just Six Numbers, Chapter 1, pg. 2</h5>
                            <p class="mb-1">
                                The cosmos is so vast because there is one crucially important huge number N in nature, equal to 1, 000, 000, 000, 000, 000, 000, 000, 000, 000, 000, 000, 000. This number measures the strength of the electrical forces that hold atoms together, divided by the force of gravity between them. <b>If N had a few less zeros, only a short-lived miniature universe could exist: no creatures could grow larger than insects, and there would be no time for biological evolution.</b> <br> <br>

                                Another number, ε, whose value is 0.007, defines how firmly atomic nuclei bind together and how all the atoms on Earth were made. Its value controls the power from the Sun and, more sensitively, how stars transmute hydrogen into all the atoms of the periodic table. Carbon and oxygen are common, whereas gold and uranium are rare, because of what happens in the stars. <b>If ε were 0.006 or 0.008, we could not exist.</b> <!-- Explained in chapter 4 under the heading The Tuning of ε -->
                            </p>
                        </blockquote>
                        <blockquote>
                            <h5 class="pt-2">Martin Rees - Just Six Numbers, Chapter 6, pg. 85</h5>
                            <p class="mb-1">
                                Suppose that, for every 10<sup>9</sup> quark-antiquark pairs, such an asymmetry had led to one extra quark. As the universe cooled, antiquarks would all annihilate with quarks, eventually giving quanta of radiation. This radiation, now cooled to very low energies, constitutes the 2.7 degree background heat pervading intergalactic space. But for every billion quarks that were annihilated with antiquarks, one would survive because it couldn't find a partner to annihilate with. There are indeed more than a billion times more radiation quanta (photons) in the universe than there are protons (412 million photons in each cubic metre, compared with about 0.2 protons). So all the atoms in the universe could result from a tiny bias in favour of matter over antimatter. <b>We, and the visible universe around us, may exist only because of a <i>difference in the ninth decimal place</i> between the numbers of quarks and of antiquarks.</b>
                            </p>
                        </blockquote>
                        <blockquote>
                            <h5 class="pt-2">Martin Rees - Just Six Numbers, Chapter 6, pg. 88-89</h5>
                            <p class="mb-1">
                                In this perspective, it looks surprising that our universe was initiated with a very finely tuned impetus, almost exactly enough to balance the decelerating tendency of gravity. It's like sitting at the bottom of a well and throwing a stone up so that it just comes to a halt exactly at the top - <b>the required precision is astonishing: at one second after the Big Bang, Ω (the cosmic density parameter) cannot have differed from unity by more than one part in a million billion (one in 10<sup>15</sup>) in order that the universe should now, after ten billion years, be still expanding and with a value of Ω that has certainly not departed wildly from unity.</b> <br> <br>

                                We have already noted that any complex cosmos must incorporate a 'large number' N reflecting the weakness of gravity, and must also have a value of ε that allows nuclear and chemical processes to take place. But these conditions, though necessary, are not sufficient. Only a universe with a 'finely tuned' expansion rate can provide the arena for these processes to unfold. So Ω must be added to our list of crucial numbers. It had to be tuned amazingly close to unity in the early universe. If expansion was too fast, gravity could never pull regions together to make stars or galaxies; if the initial impetus were insufficient, a premature Big Crunch would quench evolution when it had barely begun.
                            </p>
                        </blockquote>
                        <blockquote>
                            <h5 class="pt-2">Martin Rees - Just Six Numbers, Chapter 8, pg. 115</h5>
                            <p class="mb-1">
                                If Q (amplitude of the primordial density fluctuations) were smaller than 10<sup>−6</sup>, gas would never condense into gravitationally bound structures at all, and such a universe would remain forever dark and featureless, even if its initial 'mix' of atoms, dark matter and radiation were the same as in our own. <br> <br>
                                
                                On the other hand, a universe where Q were substantially larger than 10<sup>−5</sup> - where the initial 'ripples' were replaced by large-amplitude waves - would be a turbulent and violent place. Regions far bigger than galaxies would condense early in its history. They wouldn't fragment into stars but would instead collapse into vast black holes, each much heavier than an entire cluster of galaxies in our universe. Any surviving gas would get so hot that it would emit intense X-rays and gamma rays. Galaxies (even if they managed to form) would be much more tightly bound than the actual galaxies in our universe. Stars would be packed too close together and buffeted too frequently to retain stable planetary systems. (For similar reasons, solar systems are not able to exist very close to the centre of our own galaxy, where the stars are in a close-packed swarm compared with our less central locality.)
                            </p>
                        </blockquote>
                        <h4 class="pt-2">Leonard Susskind</h4>
                        <ul style="font-size:large">
                            <li>Leonard Susskind earned a PhD in physics from Cornell University, and served as a professor at Stanford University. He is regarded as one of the fathers of String Theory</li>
                        </ul>
                        <!-- <blockquote>
                            <h5 class="pt-2">Leonard Susskind - The Cosmic Landscape, Introduction</h5>
                            <p class="mb-1">
                                Davies and Greenstein are serious scholars, and Hoyle was one of the great scientists of the twentieth century. As they point out, the appearance of intelligent design is undeniable. Extraordinary coincidences <i>are</i> required for life to be possible. It will take us a few chapters to fully understand this "elephant in the room," but let's begin with a sneak preview.
                            </p>
                        </blockquote> -->
                        <!-- <blockquote>
                            <h5 class="pt-2">Leonard Susskind - The Cosmic Landscape, Introduction</h5>
                            <p class="mb-1">
                                The Laws of Physics begin with a list of elementary particles like electrons, quarks, and photons, each with special properties such as mass and electric charge. These are the objects that everything else is built out of. No one knows why the list is what it is or why the properties of these particles are exactly what they are. An infinite number of other lists is equally possible. But a universe filled with life is by no means a generic expectation. Eliminating any of these particles (electrons, quarks, or photons), or even changing their properties a modest amount, would cause conventional chemistry to collapse. This is obviously so for the electrons and for the quarks that make up protons and neutrons. Without these there could be no atoms at all. But the importance of the photon may be less obvious. In later chapters we will learn about the origin of forces like electric and gravitational forces, but for now it's enough to know that the electric forces that hold the atom together are consequences of the photon and its special properties. <br> <br>

                                If the laws of nature seem well chosen for chemistry, they are also well chosen for the second set of requirements, namely, that the evolution of the universe provided us with a comfortable home to live in. The large-scale properties of the universe—its size; how fast it grows; the existence of galaxies, stars, and planets—are mainly governed by the force of gravity. It's Einstein's theory of gravity—the General Theory of Relativity—that explains how the universe expanded from the initial hot Big Bang to its present large size. The properties of gravity, especially its strength, could easily have been different. In fact it is an unexplained miracle that gravity is as weak as it is.* The gravitational force between electrons and the atomic nucleus is ten thousand billion billion billion billion times weaker than the electrical attraction. Were the gravitational forces even a little stronger, the universe would have evolved so quickly that there would have been no time for intelligent life to arise. <br> <br>

                                But gravity plays a very dramatic role in the unfolding of the universe. Its pull causes the material in the universe—hydrogen, helium, and the so-called dark matter—to clump, into galaxies, stars, and finally planets. However, for this to happen, the very early universe must have been a bit lumpy. If the original material of the universe had been smoothly distributed, it would have stayed that way for all time. In fact, fourteen billion years ago, the universe was just lumpy enough—a bit lumpier or a bit less lumpy, and there would have been no galaxies, stars, or planets for life to evolve on. <br> <br>

                                Finally, there is the actual chemical composition of the universe. In the beginning there were only hydrogen and helium: certainly not sufficient for the formation of life. Carbon, oxygen, and all the others came later. They were formed in the nuclear reactors in the interiors of stars. But the ability of stars to transmute hydrogen and helium into the all-important carbon nuclei was a very delicate affair. Small changes in the laws of electricity and nuclear physics could have prevented the formation of carbon. <br> <br>

                                Even if the carbon, oxygen, and other biologically important elements were formed inside stars, they had to get out in order to provide the material for planets and life. Obviously we cannot live in the intensely hot cores of stars. How did the material escape the stellar interior? The answer is that it was violently ejected in cataclysmic supernova explosions. <br> <br>

                                Supernova explosions themselves are remarkable phenomena. In addition to protons, neutrons, electrons, photons, and gravity, supernovae require yet another particle—the ghostly neutrino previously mentioned. The neutrinos, as they escape from the collapsing star, create a pressure that pushes the elements in front of them. And, fortunately, the list of elementary particles happens to include neutrinos with the right properties.
                            </p>
                        </blockquote> -->
                        <blockquote>
                            <h5 class="pt-2">Leonard Susskind - The Cosmic Landscape, Chapter 2</h5>
                            <p class="mb-1">
                                The vacuum energies of fermions and bosons do not cancel, and the bottom line is that our best theory of elementary particles predicts vacuum energy whose gravitational effects would be vastly too large. We don't know what to make of it. Let me put the magnitude of the problem in perspective. Let's invent units in which 10<sup>116</sup> joules per cubic centimeter is called one Unit. Then each kind of particle gives a vacuum energy of roughly a Unit. The exact value depends on the mass and other properties of the particle. Some of the particles give a positive number of Units, and some negative. They must all add up to some incredibly small energy density in Units. In fact a vacuum energy density bigger than .00000...(110 more zeroes)...00001 Units would conflict with astronomical data. For a bunch of numbers, none of them particularly small, to cancel one another to such precision would be a numerical coincidence so incredibly absurd that there must be some other answer. <br> <br>

                                Theoretical physicists and observational cosmologists have regarded this problem differently. The traditional cosmologists have generally kept an open mind about the possibility that there may be a tiny cosmological constant. In the spirit of experimental scientists, they have regarded it as a parameter to be measured. <b>The physicists, myself included, looked at the absurdity of the required coincidence and said to themselves (and each other) that there must be some deep hidden mathematical reason why the cosmological constant must be exactly zero. This seemed more likely than a numerical cancellation of 119 decimal places for no good reason. We have sought after such an explanation for almost half a century with no luck.</b> <br> <br>
                                
                                String theorists are a special breed of theoretical physicist with very strong opinions about this problem. The theory that they work on has often produced unexpected mathematical miracles, perfect cancellations for deep and mysterious reasons. Their view (and it was, until not too long ago, also my view) has been that String Theory is such a special theory that it must be the one true theory of nature. And being true, it must have some profound mathematical reason for the supposed fact that the vacuum energy is exactly zero. Finding the reason has been regarded as the biggest, most important, and most difficult problem of modern physics. No other phenomenon has puzzled physicists for as long as this one. Every attempt, be it in quantum field theory or in String Theory, has failed. It truly is the mother of all physics problems.
                            </p>
                        </blockquote>
                        <blockquote>
                            <h5 class="pt-2">Leonard Susskind - The Cosmic Landscape, Chapter 2</h5>
                            <p class="mb-1">
                                In any case Weinberg set out to see if he could find a reason why a cosmological constant much bigger than 10<sup>-120</sup> Units would prevent life....  <br><br>

                                But because these density contrasts were initially so small, even a very tiny amount of repulsion could reverse the tendency to cluster. Weinberg found that if the cosmological constant were just an order of magnitude or two bigger than the empirical bound, no galaxies, stars, or planets would ever have formed!... <br> <br>

                                If the negative cosmological constant were too large, the crunch would not allow the billions of years necessary for life like ours to evolve. Thus, there is an anthropic bound on negative λ to match Weinberg's positive bound. In fact the numbers are fairly similar. If the cosmological constant is negative, it must also not be much bigger than 10<sup>-120</sup> Units if life is to have any possibility of evolving.
                            </p>
                        </blockquote>
                        <blockquote>
                            <h5 class="pt-2">Leonard Susskind - The Cosmic Landscape, Chapter 4</h5>
                            <p class="mb-1">
                                <ul>
                                    <li>The universe is a fine-tuned thing. It grew big by expanding at an ideal rate. If the expansion had been too rapid, all of the material in the universe would have spread out and separated before it ever had a chance to condense into galaxies, stars, and planets. On the other hand, if the initial expansion had not had a sufficient initial thrust, the universe would have turned right around and collapsed in a big crunch much like a punctured balloon.</li>
                                    <li>The early universe was not too lumpy and not too smooth. Like the baby bear's porridge, it was just right. If the universe had started out much lumpier than it did, instead of the hydrogen and helium condensing into galaxies, it would have clumped into black holes. All matter would have fallen into these black holes and been crushed under the tremendously powerful forces deep in the black hole interiors. On the other hand, if the early universe had been too smooth, it wouldn't have clumped at all. A world of galaxies, stars, and planets is not the generic product of the physical processes in the early universe; it is the rare and, for us, very fortunate, exception.</li>
                                    <li>Gravity is strong enough to hold us down to the earth's surface, yet not so strong that the extra pressure in the interior of stars would have caused them to burn out in a few million years instead of the billions of years needed for Darwinian evolution to create intelligent life.</li>
                                    <li>The microscopic Laws of Physics just happen to allow the existence of nuclei and atoms that eventually assemble themselves into the large "Tinkertoy" molecules of life. Moreover, the laws are just right, so that the carbon, oxygen, and other necessary elements can be "cooked" in first-generation stars and dispersed in supernovae.</li>
                                </ul>
                                
                                The basic setup looks almost too good to be true. Rather than following a pattern of mathematical simplicity or elegance, the laws of nature seem specially tailored to our own existence. As I have repeatedly said, physicists hate this idea. But as we will see, String Theory seems to be an ideal setup to explain why the world is this way.
                            </p>
                        </blockquote>
                        <blockquote>
                            <h5 class="pt-2">Leonard Susskind - The Cosmic Landscape, Chapter 6</h5>
                            <p class="mb-1">
                                The properties of Hoyle's carbon resonance are sensitive to a number of constants of nature, including the all-important fine structure constant. <b>Just a few percent change in its value, and there would have been no carbon and no life.</b> This is what Hoyle meant when he said that "it looks as if a super-intellect has monkeyed with physics as well as with chemistry and biology." <br> <br>
                                
                                But again, it would do no good for the nuclear physics to be "just right" if the universe had no stars. Remember that a perfectly homogeneous universe would never give birth to these objects. Stars, galaxies, and planets are all the result of the slight lumpiness at the beginning. <b>Early on, the density contrast was about 10<sup>-5</sup> in magnitude, but what if it had been a little bigger or a little smaller? If the lumpiness had been much less, let's say, 10<sup>-6</sup>, in the early universe, galaxies would be small and the stars, very sparse. They would not have had sufficient gravity to hang on to the complex atoms that were spewed out by supernovae; these atoms would have been unavailable for the next generation of stars. Make the density contrast a little less than that, and no galaxies or stars would form at all.</b> <br> <br>

                                <b>What would happen if the lumpiness were larger than 10<sup>-5</sup>? A factor of one hundred larger, and the universe would be full of violent, ravenous monsters that would swallow and digest galaxies before they were even finished forming.</b> 
                            </p>
                        </blockquote>
                        <blockquote>
                            <h5 class="pt-2">Leonard Susskind - The Cosmic Landscape, Chapter 6</h5>
                            <p class="mb-1">
                                There is a lot more. The laws of particle physics include the requirement that every particle has an antiparticle. How then did the universe get to have such a large preponderance of matter over antimatter? Here is what we think happened: <br> <br>
                                
                                When the universe was very young and hot, it was filled with plasma that contained almost exactly equal amounts of matter and antimatter. The imbalance was extremely small. For every 100,000,000 antiprotons, there were 100,000,001 protons. Then, as the universe cooled, particles and antiparticles combined in pairs and annihilated into photons. <b>One hundred million antiprotons found 100,000,000 partners and, together, they committed suicide, leaving 200,000,000 photons and just 1 leftover proton. These leftovers are the stuff we are made of. Today, if you take a cubic meter of intergalactic space, it will contain about 1 proton and 200,000,000 photons. Without the slight initial imbalance, I would not be here to tell you (who would not be here to read) these things.</b>
                            </p>
                        </blockquote>
                        <!-- <blockquote>
                            <h5 class="pt-2">Leonard Susskind - The Cosmic Landscape, Chapter 6</h5>
                            <p class="mb-1">
                                Another essential requirement for life is that gravity be extremely weak. In ordinary life gravity hardly seems weak. Indeed, as we age, the daily prospect of fighting gravity gets more and more daunting. I can still hear my grandmother saying, "Oy vey, I feel like a thousand pounds." But I don't ever recall hearing her complain about electric forces or nuclear forces. Nonetheless, if you compare the electric force between the nucleus and an atomic electron with the gravitational force, you would find the electric force is about 1041 times larger. Where did such a huge ratio come from? Physicists have some ideas, but the truth is that we really don't know the origin of this humongous discrepancy between electricity and gravity despite the fact that it is so central to our existence.7 But we can ask what would have happened if gravity had been a little stronger than it is. The answer again is that we would not be here to talk about it. The increased pressure due to stronger gravity would cause stars to burn much too fast—so fast that life would have no chance to evolve. Even worse, black holes would have consumed everything, dooming life long before it began. The large gravitational pull might even have aborted the Hubble expansion and caused a big crunch very shortly after the Big Bang.
                            </p>
                        </blockquote> -->
                        <h4 class="pt-2">Paul Davies</h4>
                        <ul style="font-size:large">
                            <li>Paul Davies earned a PhD in physics from University College London, and served as professor of physics at Arizona State University</li>
                        </ul>
                        <blockquote>
                            <h5 class="pt-2">Paul Davies - The Goldilocks Enigma, Chapter 1</h5>
                            <p class="mb-1">
                                Now, it happens that to meet these various requirements, certain stringent conditions must be satisfied in the underlying laws of physics that regulate the universe, so stringent in fact that a bio-friendly universe looks like a fix - or a "put-up job," to use the pithy description of the late British cosmologist Fred Hoyle. It appeared to Hoyle as if a superintellect had been "monkeying" with the laws of physics. He was right in his impression. On the face of it, the universe does look as if it has been designed by an intelligent creator expressly for the purpose of spawning sentient beings.
                            </p>
                        </blockquote>
                        <blockquote>
                            <h5 class="pt-2">Paul Davies - The Goldilocks Enigma, Chapter 7</h5>
                            <p class="mb-1">
                                If the weak (nuclear) force were weaker, the neutrinos would lack the punch to create this explosion. If it were stronger, the neutrinos would react more vigorously with the stellar core and wouldn't escape to deliver their blow to the outer layers. Either way, the dissemination of carbon and other heavy elements needed for life via this process would be compromised.... <br> <br>

                                The upshot of these various nuclear considerations, then, is that had the weak force been either somewhat stronger or very slightly weaker, the chemical makeup of the universe would be very different, with much poorer prospects for life.
                            </p>
                        </blockquote>
                        <blockquote>
                            <h5 class="pt-2">Paul Davies - The Goldilocks Enigma, Chapter 7</h5>
                            <p class="mb-1">
                                Let me now turn to the other two forces of nature, gravitation and electromagnetism. How vital are their properties to the life story? It is easy to see why changing their strengths too much would threaten biology. If gravity were stronger, stars would burn faster and die younger: if by some magic we could make gravitation twice as strong, say, then the sun would shine more than a hundred times as brightly. Its lifetime as a stable star would fall from 10 billion to less than 100 million years, which is probably too short for life to emerge and certainly too short for intelligent observers to evolve. If electromagnetism were stronger, the electrical repulsion between protons would be greater, threatening the stability of atomic nuclei.... <br> <br>

                                Carter discovered from the theory of stellar structure that to get both sorts of stars, the ratio of the strengths of the electromagnetic and gravitational forces needs to be very close to the observed value of 10<sup>40</sup>. If gravity were a bit stronger, all stars would be radiative and planets might not form; if gravity were somewhat weaker, all stars would be convective and supernovas might never happen. Either way, the prospects for life would be diminished.
                            </p>
                        </blockquote>
                        <blockquote>
                            <h5 class="pt-2">Paul Davies - The Goldilocks Enigma, Chapter 7</h5>
                            <p class="mb-1">
                                To give you a feeling for what I am talking about, the ratio of the mass of the proton to that of the electron is 1,836.1526675 - an utterly mundane number. The neutron-to-proton mass ratio is 1.00137841870, which looks equally uninspiring. Physically, it means that the proton has very nearly the same mass as the neutron, which, as we have already seen, is about 0.1 percent heavier. Is this important? Indeed it is, and not just in determining the ratio of hydrogen to helium in the universe. The fact that the neutron's mass is coincidentally just a little bit more than the combined mass of the proton, electron, and neutrino is what enables free neutrons to decay. <b>If the neutron were even very slightly lighter, it could not decay without an energy input of some sort. If the neutron were lighter still, yet only by a fraction of 1 percent, it would have less mass than the proton, and the tables would be turned: isolated protons, rather than neutrons, would be unstable. Then protons would decay into neutrons and positrons, with disastrous consequences for life, because without protons there could be no atoms and no chemistry.</b> <br> <br>

                                Cosmology provides more remarkable examples of fine-tuning. As I have discussed, the cosmic microwave background radiation is embellished with all-important ripples or perturbations, echoes of the seeds of the large-scale structure of the universe. These seeds, remember, are thought to originate in quantum fluctuations during inflation. Numerically, the variations are small: about one part in a hundred thousand, a quantity that cosmologists denote by the letter Q. <b>Now, if Q were smaller than one hundred-thousandth - say, one millionth - this would severely inhibit the formation of galaxies and stars. Conversely, if Q were bigger - one part in ten thousand or more - galaxies would be denser, leading to lots of planet-disrupting stellar collisions. Make Q too big and you'd form giant black holes rather than clusters of stars. Either way, Q needs to sit in a rather narrow range to make possible the formation of abundant, stable, long-lived stars accompanied by planetary systems of the type we inhabit. </b> 
                            </p>
                        </blockquote>
                        <blockquote>
                            <h5 class="pt-2">Paul Davies - The Goldilocks Enigma, Chapter 7</h5>
                            <p class="mb-1">
                                How many knobs are there? The Standard Model of particle physics has about twenty undetermined parameters, while cosmology has about ten. All told, there are over thirty "knobs." As I have cautioned already, not all the parameters are necessarily independent of the others, and not all require exceptional fine-tuning for life to be possible. <b>But several certainly do: some of the examples I have given demand "knob settings" that must be fine-tuned to an accuracy of less than 1 percent to make a universe fit for life.</b> But even this sensitivity pales into insignificance compared with the biggest fine-tuning riddle of all: dark energy.
                            </p>
                        </blockquote>
                        <blockquote>
                            <h5 class="pt-2">Paul Davies - The Goldilocks Enigma, Chapter 7</h5>
                            <p class="mb-1">
                                When the value of dark energy seemed to be zero, it was at least plausible that some yet-to-be-discovered mechanism might operate to force an exact cancellation. But, as Leonard Susskind has stressed, a mechanism that cancels to one part in 120 powers of ten, and then fails to cancel after that, is something else entirely. To give the reader some idea of just how much of a fix this almost-cancellation is, let me write out the number 10<sup>120</sup> in its full glory: <br> <br>

                                1, 000, 000, 000, 000, 000, 000, 000, 000, 000, 000, 000, 000, 000, 000, 000, 000, 000, 000, 000, 000, 000, 000, 000, 000, 000, 000, 000, 000, 000, 000, 000, 000, 000, 000, 000, 000, 000, 000, 000, 000 <br> <br>
                                
                                <b>So the big fix somehow works brilliantly (if mysteriously) for 119 powers of ten, but <i>fails</i> at the 120th. </b>
                                
                                <br> <br>
                                Whatever dark energy may be - and it may just be the "natural" energy of empty space - it is dangerous. In fact, it could be the most dangerous stuff known to science. About twenty years ago Steven Weinberg pointed out that if the magnitude of the dark energy were only moderately larger than the observed value, it would have frustrated the formation of galaxies. Galaxies form by the slow aggregation of matter under the action of attractive gravitation. If this tendency were opposed by a strong enough cosmic repulsion force, galaxies would be unable to grow properly. And as I have already remarked, without galaxies there would probably be no stars or planets or life. So our existence depends on the dark energy's not being too large. A factor of ten would suffice to preclude life: if space contained ten times as much dark energy as it actually does, the universe would fly apart too fast for galaxies to form. A factor of ten may seem like a wide margin, but one power of ten on a scale of 120 is a pretty close call. The cliché that "life is balanced on a knife-edge" is a staggering understatement in this case: no knife in the universe could have an edge <i>that</i> fine. <br> <br>
                                
                                Logically, it is possible that the laws of physics conspire to create an almost but not quite perfect cancellation. But then it would be an extraordinary coincidence that <i>that</i> level of cancellation - 119 powers of ten, after all - just happened by chance to be what is needed to bring about a universe fit for life. How much chance can we buy in scientific explanation? One measure of what is involved can be given in terms of coin flipping: odds of 10<sup>120</sup> to one is like getting heads no fewer than <i>four hundred times in a row</i>. If the existence of life in the universe is completely independent of the big fix mechanism - if it's just a coincidence - then those are the odds against our being here. That level of flukiness seems too much to swallow.
                            </p>
                        </blockquote>
                        <h4 class="pt-2">Geraint Lewis and Luke Barnes</h4>
                        <ul style="font-size:large">
                            <li>Geraint F. Lewis earned a PhD in astrophysics from the University of Cambridge, and served as professor of astrophysics at the University of Sydney</li>
                            <li>Luke A. Barnes also earned his PhD in astronomy from the University of Cambridge</li>
                        </ul>
                        <blockquote>
                            <h5 class="pt-2">Lewis and Barnes - A Fortunate Universe, Chapter 1</h5>
                            <p class="mb-1">
                                Dark energy could be a number of things, including something called vacuum energy, that is, the energy present in empty space even when there are no particles. Our best theory of the structure of matter tells us that each fundamental type of matter will contribute to this vacuum energy, either positively or negatively. Alarmingly, the typical size of these contributions is larger than the amount of dark energy in our Universe by a factor of 1 followed by 120 zeros, or in scientific notation 10<sup>120</sup>. <br> <br>
                                
                                <b>What would happen if the amount of dark energy in our Universe were, say, a trillion (10<sup>12</sup>) times larger? This sounds like a big increase, but it is a pittance compared to 10<sup>120</sup>. In that universe, the expansion of space would be so rapid that no galaxies, stars or planets would form. </b>The universe would contain a thin soup of hydrogen and helium. At most, these particles might occasionally bounce off each other, and head back out into space for another trillion years of lonely isolation.
                            </p>
                        </blockquote>
                        <blockquote>
                            <h5 class="pt-2">Lewis and Barnes - A Fortunate Universe, Chapter 2</h5>
                            <p class="mb-1">
                                The Delta-Plus-Plus Universe: Let's start by increasing the mass of the down quark by a factor of about 70. Down quarks would readily transform into up quarks (and other stuff), even inside protons and neutrons. Thus, they would rapidly decay into the new 'most stable' title-holder, our old friend the Δ++ particle. We would find ourselves in the 'Delta-plus-plus universe'. <br> <br>
                                
                                As we've seen, the Δ++ particle is a baryon containing three up quarks. Unlike the proton and neutron, however, the extra charge, and hence electromagnetic repulsion, on the Δ++ particles makes them much harder to bind together. Individual Δ++ particles can capture two electrons to make a helium-like element. And this will be the only element in the universe. Farewell, periodic table! The online PubChem database in our Universe lists 60, 770, 909 chemical compounds (and counting); in the Δ++ universe it would list just one. And, being like helium, it would undergo zero chemical reactions. <br> <br>
                                
                                The Delta-Minus Universe: Beginning with our Universe again, let's instead increase the mass of the up quark by a factor of 130. Again, the proton and neutron will be replaced by one kind of stable particle made of three down quarks, known as the Δ−. Within this Δ− universe, with no neutrons to help dilute the repulsive force of their negative charge, there again will be just one type of atom, and, in a dramatic improvement on the Δ++ universe, one chemical reaction! Two Δ− particles can form a molecule, assuming that we replace all electrons with their positively charged alter-ego, the positron. <br> <br>
                                
                                The Hydrogen Universe: To create a hydrogen-only universe, we increase the mass of the down quark by at least a factor of 3. Here, no neutron is safe. Even inside nuclei, neutrons decay. Once again, kiss your chemistry textbook goodbye, as we'd be left with one type of atom and one chemical reaction. <br> <br>
                                
                                The Neutron Universe: If you think the hydrogen universe is rather featureless, let's instead increase the mass of the up quark by a factor of 6. The result is that the proton falls apart. In a reversal of what we see in our Universe, the proton, including protons buried in the apparent safety of the atomic nucleus, decay into neutrons, positrons and neutrinos. This is by far the worst universe we've so far encountered: no atoms, no chemical reactions. Just endless, featureless space filled with inert, boring neutrons. <br> <br>
                                
                                There is more than one way to create a neutron universe. Decrease the mass of the down quark by just 8 per cent and protons in atoms will capture the electrons in orbit around them, forming neutrons. Atoms would dissolve into clouds of featureless, chemical-free neutrons. <br> <br>
                                
                                What about the other particle of everyday stuff, the electron? Since the electron (and its antiparticle, the positron) is involved in the decay of neutron and proton, it too can sterilize a universe. For example, increase its mass by a factor of 2.5, and we're in the neutron universe again.
                            </p>
                        </blockquote>
                        <!-- <blockquote>
                            <h5 class="pt-2">Lewis and Barnes - A Fortunate Universe, Chapter 2</h5>
                            <p class="mb-1">
                                What if electrons were bosons rather than fermions? The result would be disastrous as there would be nothing to prevent all the electrons occupying the lowest level in an atom, like stuffing as many photons in the box as you can. Once again, wave chemistry - and the chemical complexity and flexibility needed by life - goodbye. <br> <br>

                                These bosonic electrons would be very tightly bound to their nuclei, with little inclination to be shared with other atoms. This universe would be a sea of individual atoms floating through the cosmos, minding their own business and not getting involved in this messy work of forming molecules.
                            </p>
                        </blockquote> -->
                        <!-- <blockquote>
                            <h5 class="pt-2">Lewis and Barnes - A Fortunate Universe, Chapter 2</h5>
                            <p class="mb-1">
                                There is a natural, unavoidable jiggling in all objects, which comes from quantum mechanics. Unlike heating, this jiggling is a fundamental property of the quantum world, preventing us from ever cooling something to absolute zero as this would require the atoms in our lattice to be completely still. In our Universe, this jiggling is relatively gentle and won't melt objects so long as electrons are much lighter than protons. The quantum jiggling will cause electrons to buzz around the nuclei, but they're too light (1836.15 times lighter than the proton) to knock nuclei out of the lattice. And so, solid materials stay solid as long as the temperature is sufficiently low. <br> <br>
                                
                                <b>However, if the electron mass were within a factor of a hundred of the proton mass, the quantum jiggling of electrons would destroy the lattice. In short: no solids. No solid planets, no stable DNA molecules, no bones, no semi-permeable living cell walls, no organs. A complete mess, and almost certainly no life!</b>
                            </p>
                        </blockquote> -->
                        <blockquote>
                            <h5 class="pt-2">Lewis and Barnes - A Fortunate Universe, Chapter 2</h5>
                            <p class="mb-1">
                                So, the mass of the Higgs boson presents us with a conundrum. Our quantum mechanical calculations predict that it should have a mass of 10<sup>18</sup> GeV. Life requires a value not too much different to what we observe, so that the masses of the fundamental particles are not disastrously large. There must be an as yet unknown mechanism that slices off the contributions from the quantum vacuum, reducing it down to the observed value. This slicing has to be done precisely, not too much and not so little as to destabilize the rest of particle physics. This is a cut as fine as one part in 10<sup>16</sup>. Maybe there is a natural solution to this cutting, but it seems quite lucky for our Universe that the slicing resulted in stable particle physics. This problem - known as the hierarchy problem - keeps particle physicists awake at night.
                            </p>
                        </blockquote>
                        <blockquote>
                            <h5 class="pt-2">Lewis and Barnes - A Fortunate Universe, Chapter 3</h5>
                            <p class="mb-1">
                                How much would the properties of the Universe need to change in order to give us a helium universe? Consider strengthening the grip of the strong force, so that the cosmic oven becomes more efficient. Nuclei can stick together under hotter conditions, and so form earlier in the history of the Universe, when there are more neutrons. <b>Our Universe burns 25 per cent of its hydrogen in the first few minutes. An increase of the strong force by a factor of about 2 is enough to cause the Universe to burn more than 90 per cent of its hydrogen.</b>
                            </p>
                        </blockquote>
                        <!-- <blockquote>
                            <h5 class="pt-2">Lewis and Barnes - A Fortunate Universe, Chapter 3</h5>
                            <p class="mb-1">
                                The other important factors in this story are the masses of the proton and neutron. Because the neutron is heavier (see Chapter 2), the proton is stable and more abundant. If the two particles had similar masses, or if the neutron were lighter, then we would have more neutrons in the early Universe, and so once again we'd lose our hydrogen.
                            </p>
                        </blockquote> -->
                        <blockquote>
                            <h5 class="pt-2">Lewis and Barnes - A Fortunate Universe, Chapter 3</h5>
                            <p class="mb-1">
                                A supervillain who threatens to dissolve our atoms and nuclei is worth taking seriously. Chemical elements that last but a moment are pretty useless for building molecules, cells and organisms and it's not difficult to arrange: <b>decrease the strength of the strong force by a factor of about 4, and the periodic table, from carbon up, is gone. They don't even α-decay. They experience fission - the nucleus simply splits into two. We could achieve the same effect by increasing the strength of electromagnetism by a factor of 16.</b> Just don't tell your local Evil Overlord. <br> <br>
                                
                                Smaller changes will result in most of the elements being radioactive, with a range of lifetimes. This creates a swath of problems for life. Each α- and β-decay transmutes one chemical element into another, and so totally changes its chemical properties. Within life's highly specialized, precisely constructed amino acids, proteins and cells, an unpredictable change of this magnitude will cause untold damage. Life will not get very far if it cannot trust chemistry.
                            </p>
                        </blockquote>
                        <!-- <blockquote>
                            <h5 class="pt-2">Lewis and Barnes - A Fortunate Universe, Chapter 3</h5>
                            <p class="mb-1">
                                So, the properties of the valley of stability, properties defined by the relative strengths of the strong, weak and electromagnetic forces, appear to be nicely balanced for life in the Universe. We have a narrow floor of stable isotopes to provide the solid and stable molecular structures needed for life, with a broader swath of longer-lived, but ultimately unstable, isotopes that can provide radioactive heating within planets like the Earth. In universes with differing strengths of these fundamental forces, the prospects for life seem at least more complicated, if not totally eliminated.
                            </p>
                        </blockquote> -->
                        <!-- <blockquote>
                            <h5 class="pt-2">Lewis and Barnes - A Fortunate Universe, Chapter 3</h5>
                            <p class="mb-1">
                                What if we were really radical and removed a fundamental force from the Universe entirely? We could do this by setting the coupling that defines the strength of a force to zero. This is generally a bad idea if you want to create a hospitable universe. <br> <br>
                                
                                Turn off gravity, and there is nothing to drive matter to collapse into galaxies, stars and planets, or indeed any structure. Turn off electromagnetism, and there is no chemistry as there is nothing to keep electrons bound to nuclei. Turn off the strong force, and there are no nuclei, and so again chemistry is doomed. We have little choice but to pick on what may seem like the most inconsequential force. Could we get away with turning off the weak force? <br> <br>
                                
                                Radioactivity has a crucial role in the generation of heat within the Earth, but even if we completely extinguished the weak force, we could still have α-decay of elements contributing to radioactive heating. But, as we have seen, the chain of radioactive decays that deposits the energy into the rocks is a mix of α- and β-decays. Without the weak force, these chains would be cut short, reducing the heating within the planet.
                            </p>
                        </blockquote> -->
                        <blockquote>
                            <h5 class="pt-2">Lewis and Barnes - A Fortunate Universe, Chapter 4</h5>
                            <p class="mb-1">
                                With all this fast living, these stars die young, rapidly burning through their nuclear fuel. Stars would burn quickly through the universe's nuclear energy, emitting radiation that is lethal to life and dying in an even more energetic and dangerous supernova explosion. In our Universe, gravity is about 10<sup>40</sup> times weaker than the strong force; if it were only 10<sup>30</sup> times weaker, typical stars would burn out in a matter of years, not tens of billions of years. <br> <br>
                                
                                Or so we thought, until Fred Adams of the University of Michigan took a closer look at stars in other universes. Fred discovered another condition on the stability of stars, a condition that narrows the stellar window as the strength of gravity increases. <b>If gravity were 10<sup>35</sup> instead of 10<sup>40</sup> times weaker than the strong force, then the window would close completely. Stable stars would not be possible at all.</b>
                            </p>
                        </blockquote>
                        <blockquote>
                            <h5 class="pt-2">Lewis and Barnes - A Fortunate Universe, Chapter 4</h5>
                            <p class="mb-1">
                                Even smaller changes might impact how stars burn. A small decrease in the strength of the strong force by about 8 per cent would render deuterium unstable. A proton can no longer stick to a neutron, and the first nuclear reaction in stars is in danger of falling apart. An increase of 12 per cent binds the diproton - a proton can stick to another proton. This gives stars a short cut, an easy way to burn fuel. If the diproton were suddenly bound within the Sun, it would burn hydrogen at a phenomenal rate, exhausting its fuel in mere moments.
                            </p>
                        </blockquote>
                        <blockquote>
                            <h5 class="pt-2">Lewis and Barnes - A Fortunate Universe, Chapter 4</h5>
                            <p class="mb-1">
                                Other than silicon, there is little hope for life based upon other elements. Boron and sulphur have been suggested, but these are very rare in the cosmos, and simply don't provide the long, linked, folding large molecules that life needs for its inner machinery and genetic blueprint. There are only 92 naturally occurring chemical elements, and carbon is by a wide margin the most suitable for life.
                            </p>
                        </blockquote>
                        <blockquote>
                            <h5 class="pt-2">Lewis and Barnes - A Fortunate Universe, Chapter 4</h5>
                            <p class="mb-1">
                                We can, therefore, ask whether the existence and properties of the carbon resonance are fine-tuned for life: if we varied the properties of the Universe, and in particular its fundamental parameters, would it still make carbon? <br> <br>
                                
                                In 1989, Mario Livio and colleagues, of the Space Telescope Science Institute, simulated the life and death of stars with slightly different resonance energies. <b>Relative to the ground state, a change of more than about 3 per cent begins to shut down carbon production.</b> In fact, this happens for two reasons - either carbon isn't made at all, or else the star burns so efficiently that a carbon is made and then immediately burned up. The carbon nucleus can capture another helium nucleus, making oxygen.
                            </p>
                        </blockquote>
                        <!-- Posted b/c I'm aware of this, but it's noted as uncertain by the authors
                        <blockquote>
                            <h5 class="pt-2">Lewis and Barnes - A Fortunate Universe, Chapter 4</h5>
                            <p class="mb-1">
                                The rate of production of carbon and oxygen is quite sensitive to the strong nuclear force. If we nudge the strength of the strong force upwards by just 0.4 per cent, stars produce a wealth of carbon, but the route to oxygen is cut off. While we have the central element to support carbon-based life, the result is a universe in which there will be very little water. <br>  <br>
                                
                                Decreasing the strength of the strong force by a similar 0.4 per cent has the opposite effect: all carbon is rapidly transformed into oxygen, providing the universe with plenty of water, but leaving it devoid of carbon....

                                As a result, a 0.4 per cent change in the strength of the strong force might not be as bad as we thought. It may take a slightly higher percentage to totally eradicate carbon or oxygen from the universe.
                            </p>
                        </blockquote> -->
                        <blockquote>
                            <h5 class="pt-2">Lewis and Barnes - A Fortunate Universe, Chapter 4</h5>
                            <p class="mb-1">
                                Evgeny Epelbaum, Hermann Krebs, Timo Lähde, Dean Lee and Ulf-G. Meißner (2011) took up the challenge and considered what would happen to carbon and oxygen production if we mess around with the fundamental properties of matter. Contrary to Weinberg's hunch, the narrowness and location of the relevant energy levels translate into quite stringent limits on the masses of the quarks. <b>A change of much more than a small percentage destroys a star's ability to create both carbon and oxygen.</b> <br><br>
                                
                                And remember from last chapter that because the quarks are already 'absurdly light', in the words of physicist Leonard Susskind (2005, p. 176), a range of mass that is a small percentage of their value in our Universe corresponds to a tiny fraction of their possible range. It is about one part in a million relative to the Higgs field, which gives them their mass. It is about one part in 10<sup>23</sup> relative to the Planck mass! <br><br>
                                
                                So the fact that we are here typing these words, and you are there reading them, all constructed from molecules of carbon and oxygen, is only possible because the masses of the quarks and the strength of the forces lie within an outrageously narrow range!
                            </p>
                        </blockquote>
                        <!-- <blockquote>
                            <h5 class="pt-2">Lewis and Barnes - A Fortunate Universe, Chapter 4</h5>
                            <p class="mb-1">
                                There are two reasons. Firstly, we aren't totally sure that the Big Bang was the beginning of the Universe. If someone comes up with an alternative theory of what happened in the early Universe that explains why it started in such a seemingly special state, then this would explain a great mystery. However, the odds are stacked against such an approach. Given the second law of thermodynamics - that entropy only increases - any explanation of the 'beginning' of our Universe in terms of a yet earlier state would need that state to be even more special!
                            </p>
                        </blockquote> -->
                        <!-- <blockquote>
                            <h5 class="pt-2">Lewis and Barnes - A Fortunate Universe, Chapter 5</h5>
                            <p class="mb-1">
                                For reasons that we do not understand, the very early Universe contains about a billion and one particles for every billion antiparticles. This may not seem like much, but we are all made from those billion-and-first particles. When matter and antimatter annihilate as the Universe cools, a remnant remains. From this, our Universe is made.
                            </p>
                        </blockquote> -->
                        <!-- <blockquote>
                            <h5 class="pt-2">Lewis and Barnes - A Fortunate Universe, Chapter 5</h5>
                            <p class="mb-1">
                                The cosmological constant problem is not as straightforward as 'prediction gone wrong'. Vacuum energies can be positive or negative, so summing all the different energies could miraculously make them cancel each other out to 120 decimal places. But still, it's not very likely. <br> <br>
                                
                                As an example of fine-tuning, the cosmological constant problem is a near-perfect storm. This is important so, in some detail, here's why. <br> <br>

                                1. It's actually several problems. Each quantum field - electron, quark, photon, neutrino, etc. - adds a ludicrously large contribution to the vacuum energy of the universe.
                                
                                2. General Relativity won't help. Einstein's theory links energy and momentum to spacetime geometry. It does not dictate what energy and momentum exists in the Universe. Universes that are no good for life are perfectly fine by the principles of General Relativity.
                                
                                3. Particle physics probably won't help. Particle physics processes - those described by quantum field theory - depend only on energy differences. We can change the absolute values of all the energies in particle physics and all the interactions remain the same. It is only gravity that cares about absolute energies. Thus, particle physics is largely blind to its effect on cosmology, and thereby life.
                                
                                4. It isn't just a problem at the Planck scale, so quantum gravity won't necessarily help. As noted above, we don't need to trust quantum field theory all the way up to the Planck energy in order to see the cosmological constant problem. It is entrenched firmly within well-understood, well-tested physics.
                                
                                5. Alternative forms of dark energy have exactly the same problem. Dark energy - whatever is making the expansion of the Universe accelerate - might not be vacuum energy. But alternative forms of dark energy usually posit some other kind of field, and so the problem of the vacuum energy of the field returns, unchanged and unsolved.
                                
                                6. We can't aim for zero. Before the accelerated expansion of the Universe was discovered, it was thought that some principle or symmetry would set the cosmological constant to zero. Even this was a speculative hope, and it has since evaporated.
                                
                                7. The quantum vacuum has observable consequences, and so cannot be dismissed as mere fiction. In particular, an electron in an atom feels the influence of the surrounding quantum vacuum.11 Our theory works beautifully for electrons and atoms. Why doesn't cosmic expansion feel the full influence of the quantum vacuum?
                                
                                8. The (effective) cosmological constant is clearly fine-tuned. It's just about the best fine-tuning case around. There is no simpler way to make a universe lifeless than to make it devoid of any structure whatsoever. Make the cosmological constant just a few orders of magnitude larger and the universe will be a thin, uniform hydrogen and helium soup, a diffuse gas where the occasional particle collision is all that ever happens. Particles spend their lives alone, drifting through emptying space, not seeing another particle for trillions of years and even then, just glancing off and returning to the void.
                                
                                And that's why we need help!
                            </p>
                        </blockquote> -->
                        <blockquote>
                            <h5 class="pt-2">Lewis and Barnes - A Fortunate Universe, Chapter 5</h5>
                            <p class="mb-1">
                                While the expansion of a universe decelerates, curved universes become more curved. Exactly flat universes remain flat, but the slightest curvature is quickly amplified. Because (according to the Standard Cosmology) our Universe was decelerating for the first few billion years of its existence, its initial conditions must be preposterously fine-tuned for it to appear flat today. Suppose we wind the tape of the Universe back to when the first elements are formed, a few minutes after the Big Bang. Then, in order for our Universe to be flat to within one per cent today, it must have been flat to within one part in a thousand trillion (1 followed by 15 zeros). Suspicious! <br> <br>
                                
                                Winding the clock further back in time only makes it worse. The furthest we can meaningfully wind the clock back is the so-called Planck time, before which we would need a theory of quantum gravity to predict what's going on. (We don't have one. Or at least, not one that is well understood and well tested.) The Planck time is equal to 10<sup>−44</sup> seconds. At this time, the fine-tuning is one part in 10<sup>55</sup>. Even more suspicious! <br> <br>
                                
                                This is known as the flatness problem. It is a problem for cosmology. It is a problem for life, too.
                            </p>
                        </blockquote>
                        <blockquote>
                            <h5 class="pt-2">Lewis and Barnes - A Fortunate Universe, Chapter 5</h5>
                            <p class="mb-1">
                                Thanks to the fine-tuning of the initial density of the universe, it doesn't take much to induce a suicidal expansion. <b>If we look at the density of the Universe just one nanosecond after the Big Bang, it was immense, around 10<sup>24</sup> kg per cubic metre. This is a big number, but if the Universe was only a single kg per cubic metre higher, the Universe would have collapsed by now. And with a single kg per cubic metre less the Universe would have expanded too rapidly to form stars and galaxies.</b>
                            </p>
                        </blockquote>
                        <blockquote>
                            <h5 class="pt-2">Lewis and Barnes - A Fortunate Universe, Chapter 5</h5>
                            <p class="mb-1">
                                The almost-uniform temperature of the CMB implies that the early Universe was almost smooth. The density of the Universe departed from the average density by at most one part in 100,000. This number (1 in 100,000) is known as Q. We have no idea why it has this value, but this smoothness of our Universe is essential for life.... <br><br>

                                <!-- By decreasing Q by a factor of 10 to one part in a million, ordinary matter remains diffuse, hot and unbothered. No dark matter halo is home to rapid, runaway gas cooling. The pressure of this hot matter holds gravity at bay, preventing collapse and fragmentation into stars. No stars means no planets and no life. <br><br>
                                
                                If we wind the value of Q upwards from one part in 100,000, what would be the effect? Clearly, with a larger Q, gravity has more to work with, and regions would condense and collapse in the early stages of the universe. Gas in these massive proto-galaxies would collapse and form stars, but more and more stars would be packed into smaller regions, with this close-packing resulting in many star-star close encounters, which would destroy the prospects of forming planets in stable orbits. <br><br>
                                
                                Taking Q to even larger values would result in gravity collapsing immense regions of the universe into extremely massive black holes, each weighing more than thousands of individual galaxies. In such a universe, all of the raw material for stars, planets and life would be locked away behind the one-way horizons of these black holes, and the universe would be dead and sterile. <br><br> -->
                                
                                How large does Q have to be before we create such catastrophic universes? Not large at all. If Q were one part in 10,000, then nearby stars would disrupt planets in their orbits. And if Q were one part in 100, then black holes would abound. 
                                
                                <!-- So, the value of Q, the initial lumpiness in the Universe, needs to be tuned to a high degree to ensure a reasonably sedate beginning to the formation of structure, but not so sedate that it does not occur at all. -->
                            </p>
                        </blockquote>
                        <!-- <blockquote>
                            <h5 class="pt-2">Lewis and Barnes - A Fortunate Universe, Chapter 5</h5>
                            <p class="mb-1">
                                As matter and radiation flood back into the universe, they mustn't be too smooth or too lumpy. Recall from our discussion above that life needs a very specific amount of lumpiness: Q between one part in 1,000,000 and one part in 10,000.
                            </p>
                        </blockquote> -->
                        <blockquote>
                            <h5 class="pt-2">Lewis and Barnes - A Fortunate Universe, Chapter 5</h5>
                            <p class="mb-1">
                                But how big a change can we make? Well, not that much. As we've seen, neutrinos are about one millionth of the mass of the electron, the next most massive particle. Tegmark and collaborators showed that increasing the neutrino mass by even a factor of a couple will have a devastating effect on galaxy formation, effectively suppressing it completely and leaving the universe nothing but a smooth soup of shapeless matter.
                            </p>
                        </blockquote>
                        <!-- <blockquote>
                            <h5 class="pt-2">Lewis and Barnes - A Fortunate Universe, Chapter 5</h5>
                            <p class="mb-1">
                                But this is precisely what is missing for almost all other fine-tuning cases. Draw the number line for the quark masses, for the electron mass, for Q, for the strengths of the forces - in none of them will you find a target, a special value waiting inside the life-permitting region. There is nothing at which to aim; physics is blind to what life needs. And yet, here we are.
                            </p>
                        </blockquote> -->
                        <blockquote>
                            <h5 class="pt-2">Lewis and Barnes - A Fortunate Universe, Chapter 6</h5>
                            <p class="mb-1">
                                Overall, the Universe is electrically neutral. If the contents of some patch of the Universe were to somehow become predominately positively charged, the corresponding negative charges must be elsewhere in the Universe. The two regions will be drawn together, eventually meeting, mingling, and restoring local electrical neutrality. <br> <br>
                                
                                It's important to realize just how precisely electric neutrality needs to be enforced. Suppose that you were assembling Earth and got a little careless with your book-keeping, so that for every trillion trillion trillion protons and electrons you put into the mix, one extra electron slipped in. The combined repulsion of these extra electrons would be stronger than the attraction of gravity. The Earth would not be gravitationally bound. <br> <br>
                                
                                In fact, the same net charge (one part in 10<sup>36</sup>) would preclude any gravitationally bound structure in the Universe at all. Galaxies, stars and planets would all fail to collapse under their own gravity, instead being dispersed by electromagnetic repulsion. The result: a universe of extremely diffuse gas, and not much else.
                            </p>
                        </blockquote>


                        <h4 class="pt-2">Fine-Tuning in the Physical Universe - Various Authors</h4>
                        <ul style="font-size:large">
                            <li>In 2020, Cambridge University Press published a collaborative work on fine-tuning entitled <i>Fine-Tuning in the Physical Universe</i></li>
                            <li>The editors of the work are:
                                <ul>
                                    <li>David Sloan - Earned a PhD in physics from Penn State University, and served as faculty at Oxford and Cambridge University </li>
                                    <li>Rafael Alves Batista - Earned a PhD in physics from the University of Hamburg, and did research at Oxford</li>
                                    <li>Michael Townsend Hicks - Earned a PhD in philosophy from Rutgers University, and was staff at Oxford University</li>
                                    <li>Roger Davies - Earned a PhD in astronomy from the University of Cambridge, served as professor of astrophysics at the University of Oxford</li>
                                </ul>
                            </li>
                            <li>The authors of the chapters cited in this article are:
                                <ul>
                                    <li>Mario Livio - Earned a PhD in theoretical astrophysics at Tel Aviv University, and worked with the Hubble Space Telescope for over 20 years</li>
                                    <li>Martin Rees - As mentioned above, he earned a PhD in astronomy from the University of Cambridge, and served as a professor at Cambridge</li>
                                    <li>Bernard Carr - Earned a PhD in cosmology from the University of Cambridge, served as professor of astronomy at Queen Mary University of London</li>
                                    <li>Adrianne Slyz - Earned a PhD in science from Columbia University, served as a professor at Oxford University</li>
                                </ul>
                            </li>
                        </ul>
                        <blockquote>
                            <h5 class="pt-2">Mario Livio and Martin Rees - Fine-Tuning in the Physical Universe, Chapter 1, pg. 9-10</h5>
                            <p class="mb-1">
                                The parameter that measures the 'roughness' of the Universe is called Q. At recombination, the temperature fluctuations across the sky T/T are of order Q. There is no firm theoretical argument that explains why it has the observed value of about 10<sup>-5</sup>... <br> <br>

                                The conclusion from this discussion (summarised also in [25]; see Figure 1.3) is that for a universe to be conducive for complexity and life, the amplitude of the fluctuations should best be between 10<sup>-6</sup> and 10<sup>-4</sup> and, therefore, not particularly finely tuned.
                            </p>
                        </blockquote>
                        <blockquote>
                            <h5 class="pt-2">Bernard Carr - Fine-Tuning in the Physical Universe, Chapter 2, pg. 42</h5>
                            <p class="mb-1">
                                Once the suggestion was made, the resonance was looked for in the laboratory and rapidly found. So this might be regarded as the first confirmed anthropic prediction, although Kragh [53] takes a different view. Indeed, the fine-tuning required is so precise that Hoyle concluded that the Universe has to be a 'put-up job'. At the time, it was not possible to quantify this coincidence, but more recent work has studied this more carefully [6, 25, 37, 56]. <b>In particular, studies by Oberhummer et al. - calculating the variations in oxygen and carbon production in red giant stars as one varies the strength and range of the nucleon interactions - indicates that the nuclear interaction strength must be tuned to at least 0.5% [58].</b>
                            </p>
                        </blockquote>
                        <blockquote>
                            <h5 class="pt-2">Bernard Carr - Fine-Tuning in the Physical Universe, Chapter 2, pg. 42-43</h5>
                            <p class="mb-1">
                                As discussed in detail by Barrow and Tipler [11], many features of chemistry are sensitive to the value of αS. For example, if αS were increased by 2%, all the protons in the Universe would combine at cosmological nucleosynthesis to form diprotons (nuclei consisting of two protons). In this case, there would be no hydrogen and, hence, no hydrogen-burning stars. Since stars would then have a much reduced main-sequence time, there might not be time for life to arise. If αS were increased by 10%, the situation would be even worse because everything would go into nuclei of unlimited size, and there would be no interesting chemistry. The lack of chemistry would also apply if αS was decreased by 5% because all deuterons would then be unbound, and one could only have hydrogen.
                            </p>
                        </blockquote>
                        <blockquote>
                            <h5 class="pt-2">Bernard Carr - Fine-Tuning in the Physical Universe, Chapter 2, pg. 53</h5>
                            <p class="mb-1">
                                Since many models of particle physics invoke extra spatial dimensions, the issue of why we live in a world with three spatial dimensions naturally arises. While there may well be some physical explanation for this, it clearly has anthropic aspects. For example, there would be no gravity with two spatial dimensions, and planetary orbits would be unstable with four of them. There are also constraints on the number of time dimensions, associated with causality. Other arguments for the number of space and time dimensions have been given by Tegmark [79], and Figure 2.10 is taken from his paper.
                            </p>
                        </blockquote>
                        <!-- <blockquote>
                            <h5 class="pt-2">John Peacock - Fine-Tuning in the Physical Universe, Chapter 3, pg. 98</h5>
                            <p class="mb-1">
                                This leads us in the direction of anthropic arguments, which are able to limit to some extent: if the Universe had become vacuum dominated at z > 1,000, gravitational instability would have been impossible - so that galaxies, stars, and observers would not have been possible [56]. Indeed, Weinberg made the astonishingly prescient prediction on this basis that a non-zero vacuum density would be detected at v of order unity, since there was no reason for it to be much smaller.
                            </p>
                        </blockquote> -->
                        <blockquote>
                            <h5 class="pt-2">Adrianne Slyz - Fine-Tuning in the Physical Universe, Chapter 6, pg. 232</h5>
                            <p class="mb-1">
                                There are many places where one could see fine-tuning at work in cosmological structure formation, beginning with the initial conditions from which structures come into existence. Indeed, it may seem paradoxical that the very mechanism invoked to solve, amongst other issues, the acausal fine-tuning problem, turns out to appear so fine-tuned itself. In other words, why is the value of the initial fluctuation amplitudes produced by inflation so low (one part in 100,000)? <br> <br>
                                
                                Should they be much smaller, despite the presence of dark matter, they would remain in the linear regime, and galaxies would not have enough time to grow. If, on the other hand, they were much larger, say on the order of unity, they would never grow in the linear regime to begin with, but behave like independent universes very rapidly collapsing on top of one another, creating a very violent environment where galaxy cannibalism would be the rule rather than the exception. As a result, this would greatly reduce the total number of galaxies in the Universe and, hence, the number of places where life could be nurtured.
                            </p>
                        </blockquote>
                        <!-- Section on pg. 259 beginning with "The existence of stable atoms" may be worth more investigation -->
                        <!-- <blockquote>
                            <h5 class="pt-2">Joseph Silk - Fine-Tuning in the Physical Universe, Chapter 10, pg. 408</h5>
                            <p class="mb-1">
                                The most direct evidence for fine-tuning is usually associated with the adopted strength of gravity. If the gravitational constant is too low, stars do not evolve sufficiently to produce the carbon needed for life. On the larger scales, galaxies provide the backdrop for star formation. Here, the most relevant parameter is the strength of the initial density fluctuations, often attributed to inflation-boosted quantum fluctuations (see Chapter 4). Over a modest range, this determines the abundance of galaxies and their epoch of formation. <br> <br>
                                
                                If, however, one varies the fluctuation strength by an order of magnitude or more, one runs into serious problems. If the initial fluctuations are much too large, the Universe contains relatively few galaxies but predominantly supermassive black holes. If the fluctuations are much too small, there are no galaxies [47]. The fluctuation strength is a phenomenological parameter that cannot be directly related to fundamental constants; rather, it is a product of inflation and of poorly constrained inflationary physics.
                            </p>
                        </blockquote> -->
                        <!-- <blockquote>
                            <h5 class="pt-2">George Ellis, Jean-Philippe Uzan, David Sloan - Fine-Tuning in the Physical Universe, Chapter 13, pg. 535</h5>
                            <p class="mb-1">
                                If physics uniquely leads to molecules compatible with life in this way, then in some sense, physics foresees the existence of life. <br> <br>
                                
                                Why? This is a conundrum: <i>physics seems fine-tuned to expect life.</i>
                            </p>
                        </blockquote> -->
                        <!-- <blockquote>
                            <h5 class="pt-2">George Ellis, Jean-Philippe Uzan, David Sloan - Fine-Tuning in the Physical Universe, Chapter 13, pg. 536</h5>
                            <p class="mb-1">
                                We do not believe life could come into existence without being based in carbon and its huge variety of organic molecules that allow extraordinary complexity of function, as characterised by the possibility spaces of molecular biology [32].
                            </p>
                        </blockquote> -->
                        <h4 class="pt-2">Hugh Ross</h4>
                        <ul style="font-size:large">
                            <li>Hugh Ross earned a PhD in astronomy from the University of Toronto, and did postdoctoral research at Caltech for 5 years. He is listed at the bottom of this article because although he is an expert in his field, he is a Christian apologist, which some nonbelievers will no doubt use to dismiss him, despite his expertise</li>
                            <li>In addition to the citations below, Ross has compiled a 300 page compendium of fine-tuning data for the universe as well as the earth, which includes hundreds of references to scientific works: <a href="https://reasons.org/explore/publications/articles/rtb-design-compendium-2009" target="_blank">Reasons to Believe - Design Compendium</a></li>
                        </ul>
                        <blockquote>
                            <h5 class="pt-2">Hugh Ross - The Creator and the Cosmos, Chapter 15</h5>
                            <p class="mb-1">
                                How delicate is the balance for the strong nuclear force? <b>If the strong nuclear force were just 4% stronger, the diproton (an atom with two protons and no neutrons) would form. Diprotons would cause stars to so rapidly exhaust their nuclear fuel as to make any kind of physical life impossible. On the other hand, if the strong nuclear force were just 10% weaker, carbon, oxygen, and nitrogen would be unstable and again physical life would be impossible. </b>  <br> <br>

                                Does this just apply to life as we know it? No, this holds true for any conceivable kind of life chemistry throughout the cosmos. This delicate condition must be met universally.
                            </p>
                        </blockquote>
                        <blockquote>
                            <h5 class="pt-2">Hugh Ross - The Creator and the Cosmos, Chapter 15</h5>
                            <p class="mb-1">
                                In the late 1970s and early 1980s, Fred Hoyle discovered that an incredible fine-tuning of the nuclear ground state energies for helium, beryllium, carbon, and oxygen was necessary for any kind of life to exist. <b>The ground stats energies for these elements cannot be higher or lower with respect to each other by more than 4% without yield a universe containing insufficient oxygen or carbon for life.</b> Hoyle, who has written extensively against theism and Christianity in particular, nevertheless concluded on the basis of this quadruple fine-tuning that "a superintellect has monkeyed with physics, as well as with chemistry and biology".
                            </p>
                        </blockquote>
                        <blockquote>
                            <h5 class="pt-2">Hugh Ross - The Creator and the Cosmos, Chapter 15</h5>
                            <p class="mb-1">
                                The (German-Hungarian) astrophysical team mathematically constructed models of red giant stars that adopted slightly different values of the strong nuclear force and electromagnetic force constants. They discovered that tiny adjustments in the values of either of these constants imply that red giant stars would produce too little carbon, too little oxygen, or too little of both oxygen and carbon. <b>Specifically, they determined that if the value of the coupling constant for electromagnetism were 4% smaller or 4% larger than what we observe, then life would be impossible. In the case of the coupling constant for the strong nuclear force, if it were 0.5% smaller or larger, then life would be impossible. </b>
                            </p>
                        </blockquote>
                        <blockquote>
                            <h5 class="pt-2">Hugh Ross - The Creator and the Cosmos, Chapter 15</h5>
                            <p class="mb-1">
                                In the first moments after creation, the universe contained about 10 billion and 1 nucleons for every 10 billion antinucleons. The 10 billion antinucleons annihilated the 10 billion nucleons, generating an enormous amount of energy. All the galaxies and stars that make up the universe today were formed from the leftover nucleons. If the initial excess of nucleons over antinucleons were any less, there would not be enough matter for galaxies, stars, and heavy elements to form. If the excess were any greater, galaxies would form, but they would so efficiently condense and trap radiation that none of them would fragment to form stars and planets. 
                            </p>
                        </blockquote>
                        <blockquote>
                            <h5 class="pt-2">Hugh Ross - The Creator and the Cosmos, Chapter 15</h5>
                            <p class="mb-1">
                                The neutron is 0.138% more massive than a proton. Because of this extra mass, neutrons require slightly more energy to make than protons. So as the universe cooled from the hot big bang creation event, it produced more protons than neutrons - in fact, about seven times as many. <br> <br>

                                If the neutron were just another 0.1% more massive, so few neutrons would remain from the cooling off of the big bang that there would not be enough of them to make the nuclei of all the life-essential heavy elements. The extra mass of the neutron relative to the proton also determines the rate at which neutrons decay into protons and protons build into neutrons (one neutron decays into one proton + one electron + one neutrino). If the neutron were 0.1% less massive, so many protons would be built up to make neutrons that all the stars in the universe would have rapidly collapsed into either neutron stars or black holes. <b>Thus for life to be possible in the universe, the neutron mass must be fine-tuned to better than 0.1%.</b>
                            </p>
                        </blockquote>
                        <blockquote>
                            <h5 class="pt-2">Hugh Ross - The Creator and the Cosmos, Chapter 15</h5>
                            <p class="mb-1">
                                Unless the number of electrons is equivalent to the number of protons to an accuracy of one part in 10<sup>37</sup> or better, electromagnetic forces in the universe would never have overcome gravitational forces so that galaxies, stars, and planets never would have formed. 
                            </p>
                        </blockquote>
                        <blockquote>
                            <h5 class="pt-2">Hugh Ross - The Creator and the Cosmos, Chapter 15</h5>
                            <p class="mb-1">
                                The dark energy density must be even more spectacularly fine-tuned. The original source or sources of dark energy must be at least 122 orders of magnitude larger than the amount astronomers now detect. This implies that somehow the source(s) must cancel one another so as to leave just one part in 10<sup>122</sup>. <br> <br>

                                As Lawrence Krauss and many other astrophysicists noted, this one part in 10<sup>122</sup> is by far the most extreme fine-tuning yet discovered in physics. 
                            </p>
                        </blockquote>
                        <blockquote>
                            <h5 class="pt-2">Hugh Ross - The Creator and the Cosmos, Chapter 15</h5>
                            <p class="mb-1">
                                For relativity to operate so that certain proteins containing copper and vanadium will adequately support life means that the velocity of light must be fine-tuned. This is not the only reason why the velocity of light must be held constant and fixed at the value of 299,792.458 kilometers per second. Because of Einstein's equation, <i>E = mc<sup>2</sup></i>, even small changes in <i>c</i> (the velocity of light) lead to huge changes in <i>E</i> (the energy) or <i>m</i> (the mass). Thus, a slight change in light's velocity implies that starlight will either be too strong, or too feeble for life, or that stars will produce the wrong elements for life. 
                            </p>
                        </blockquote>
                        <blockquote>
                            <h5 class="pt-2">Hugh Ross - The Creator and the Cosmos, Chapter 15</h5>
                            <p class="mb-1">
                                A fourth measured parameter, another very sensitive one, is the ratio of the electromagnetic force constant to the gravitational force constant. <b>If the electromagnetic force relative to gravity were increased by just one part in 10<sup>40</sup>, the full range of small star sizes and types needed to make life possible would not form. And, if it were decreased by just one part in 10<sup>40</sup>, the full range of large star sizes and types needed to make life possible would not form. For life to be possible in the universe, the full range of both large and small star sizes and types must exist.</b> Large stars must exist because only their thermonuclear furnaces produce most of the life-essential elements. Small stars like the Sun must exist because only small stars burn long enough and stably enough to sustain a planet with life. 
                            </p>
                        </blockquote>
                        <blockquote>
                            <h5 class="pt-2">Hugh Ross - The Creator and the Cosmos, Chapter 17</h5>
                            <p class="mb-1">
                                Everything written so far in this chapter assumes that physical life must be carbon-based. As physicist Robert Dicke observed 50 years go, if you want physicists (or any other life-forms), you must have carbon. <br> <br>

                                Arsenic, boron, and silicon are the only other elements on which complex molecules can be based, but arsenic and boron are relatively rare and, where concentrated, poisonous to life, and silicon can hold together no more than about a hundred amino acids. Only carbon yields the chemical bonding stability and bonding complexity that life requires. Given the constraints of physics and chemistry, we now know that physical life must be carbon-based.
                            </p>
                        </blockquote>
                        <section id="appendix-I"></section>
                        <h3 class="pt-2">Appendix I - Brief Responses to Arguments Against Fine-Tuning</h3>
                        <p class="article-body">
                            While many others have dealt with Atheistic challenges to the fine-tuning of the universe - see, for instance, section 7 of Robin Collins's chapter on the Teleological Argument in <i>The Blackwell Companion to Natural Theology</i><!--or Chapter 4 of William Lane Craig's book <i>Reasonable Faith</i>--> - what follows are some brief responses to the most popular arguments which are put forth:
                        </p>
                        <ul style="font-size:large">
                            <li>"If the universe did not allow for life, we would not be here to observe it. Therefore, the universe appearing to be finely-tuned is just survivorship bias"
                                <ul>
                                    <li>This is a form of the Weak Anthropic Principle, which is an <i>observation</i>, not an explanation. In other words, this answers nothing. When discussing the fine-tuning of the physical universe, we are considering <i>why</i> it seems as if this universe was created finely-tuned for life to arise, given how precariously balanced everything is. This is essentially saying "Who cares, we are here, after all", which misses the whole point of the investigation, and why we find fine-tuning compelling - thoughtful people recognize that it demands an explanation, given that it so easily could have been another way, where the existence of any life would have been an impossibility</li>
                                </ul>
                            </li>
                            <li>"We do not know whether, if one of the constants were tweaked, another would alter itself to compensate, thereby preserving a life-sustaining universe"
                                <ul>
                                    <li>If a force augmented or diminished itself so that the universe continued to sustain life, in response to the alteration of another force, that would be even more astoundingly remarkable evidence that we are not here by accident. This sort of mechanism would not only itself need to be finely-tuned, but would also require explanation - there would need to be a reason why the force alters itself, and why it does so in a way that preserves the phenomena allowing for complex life in the universe</li>
                                </ul>
                            </li>
                            <li>"We do not know the total set of constant values which would sustain life. Maybe it is a large set"
                                <ul>
                                    <li>We can perform experiments on our own situation to know that the set of life-sustaining universes is a vanishingly small subset of all potential universes. This is because all <i>necessary forces</i> - forces which need to have a non-zero value in order for complex life to exist - have an infinite set of values which render life impossible, as they go toward zero, or infinity, or both. If these values <i>must</i> be within a certain range, and cannot be any possible value, then fine-tuning is being invoked again, because that requires an explanation </li>
                                    <li>Also, consider that there are an infinite number of possible universes in which, nearly everything else being the same, electrons do not exist. Or, an infinite number of possible universes in which, nearly everything else being the same, there is no gravitational force. Etc. There is no rational basis for claiming that any fundamental particle or force "must" exist, at all, with any value, in all possible universes</li>
                                    <!-- The burden of proof lies on those who suggest that other configurations might allow for life. Until such configurations are demonstrated, the fine-tuning of our universe remains a significant observation. Without evidence of other possible life-permitting sets of constants, the argument that "there could be others" is purely speculative. -->
                                    <!--  -->
                                </ul>
                            </li>
                            <li>"These alterations only disallow life <i>as we know it</i>. We have no idea if other forms of life would arise, if these allegedly fine-tuned parameters were tweaked outside of what life <i>as we know it</i> could sustain"
                                <ul>
                                    <li>No, they do not disallow only life as we know it. Many of these fine-tuning instances disallow <i>any</i> form of life being possible, or even the formation of chemistry, or atoms - for example, the value of the Cosmological Constant, or the ratio of matter to antimatter. Similarly, if fundamental particles such as quarks, electrons, and photons did not exist, or had slightly different properties, there would be no atoms at all</li>
                                    <!-- <li>There is also strong evidence that only carbon-based life is viable. See the relevant quotes from Chapter 4 of <i>A Fortunate Universe</i>, and Chapter 17 of <i>Creator and the Cosmos</i>, above</li> -->
                                </ul>
                            </li>
                            <li>"Most of the universe has no life, and therefore, this universe is definitely not "finely-tuned" for something which exists in far less than a fraction of 1% of it"
                                <ul>
                                    <li>The universe being "finely-tuned" for life means that it allows for life to potentially exist. No one who advocates for fine-tuning is arguing that life is possible everywhere in the universe. Rather, fine-tuning advocates are pointing out that life merely being possible <i>anywhere</i> in the universe requires an amazing series of factors to align, and their alignment by chance, without any intelligent guidance, is essentially impossible</li>
                                </ul>
                            </li>
                            <li>"This universe may be one of an infinite number of universes in a multiverse. Therefore, the universe appears to be finely-tuned only because it is one of the universes in the multiverse which had everything align just right"
                                <ul>
                                    <li>This is, in essence, conceding the argument, and abandoning the battlefield. It is an admission that the universe is indeed finely-tuned, but rather than admitting that God made it, an appeal is made to an unobservable machine which somehow creates infinite universes</li>
                                    <li>There is no evidence that there is a multiverse, which is generating universes with <i>different</i> and apparently random values for all the fundamental constants, such that some of them may get "lucky" and be suitable for complex life</li>
                                    <li>The multiverse, if it existed, would be even more fantastically complex than our universe, would itself require fine-tuning, and would also need an ultimate explanation</li>
                                </ul>
                            </li>
                            <li>"Many of these forces which seem independent may turn out to be derived, meaning that they actually <i>could not</i> be any other value, as their values are ultimately determined by more fundamental forces"
                                <ul>
                                    <!-- Blackwell Companion pg. 275 has an answer to this too -->
                                    <li>Suppose <i>every force</i> is derived. Not just one or two - all of them. Suppose the reason why force X or Y or Z cannot be tweaked is because there is one force, G, causing everything to be what it is, allowing life to exist. Many questions still need answering:
                                        <ol>
                                            <li>What is the nature of G, such that it is the source of all this phenomena that we observe (Gravitation, Electromagnetism, etc.)? What exactly is it?</li>
                                            <li>Why does G exist, and persist in existing?</li>
                                            <li>Why is G such that the forces that it was responsible for causing had the values which allowed for life?</li>
                                        </ol>
                                    </li>
                                    In summary, if all the forces are derived, it is of no consequence to the force of this argument. It merely moves the explanation back one step, and over time, builds a fantastically complicated ultimate force, G, which also needs an explanation, and is arguably more inexplicable, because it is responsible for so many phenomena, all of which are so finely-tuned for life
                                </ul>
                            </li>
                        </ul>
                        <!-- Appendix II - Fine Tuning in the Life Sciences - Abiogenesis -->
                        <!-- Dr. John Lennox -->
                        <!-- https://reasons.org/explore/publications/articles/explanation-for-origin-of-life-s-molecular-handedness-is-insoluble -->
                        <!-- <blockquote>
                            <h5 class="pt-2">Cosmic Chemistry, Chapter 8</h5>
                            <p class="mb-1">
                                In any case, getting the amino acid building blocks would only be the beginning of the difficulties in the way of would-be cell-constructors. Suppose, for instance, that we want to make a protein that involves 100 amino acids (this would be a short protein - most are at least three times as long). Amino acids exist in two chiral forms that are mirror images of each other, called L and D forms. These two forms appear in equal numbers in prebiotic simulation experiments, so that the probability of getting one or other of the forms is roughly 1/2. However, the great majority of the proteins found in nature contain only the L-form. The probability of getting 100 amino acids of L-form is, therefore, (1/2)<sup>100</sup>, which is about 1 chance in 10<sup>30</sup>. <br> <br>
                                
                                Next, the amino acids have to be joined together. Functional protein requires all the bonds to be of a certain type - peptide bonds - in order for it to fold into the correct three-dimensional structure. Yet in prebiotic simulations no more than half of the bonds are peptide bonds. So the probability of a peptide bond is about 1/2, and again the probability of getting 100 such bonds is 1 in 10<sup>30</sup>. Thus the probability of getting 100 L-acids at random with peptide bonds is about 1 in 10<sup>60</sup>. In the absence of such complex information processing molecules in the prebiotic state, variable chirality, bonding, and amino acid sequence would not lead to reproducible folded states which are essential to molecular function. Of course, a short protein is much less complicated than the simplest cell for which the probabilities would consequently be very much smaller.
                            </p>
                        </blockquote> -->
                        <!-- <blockquote>
                            <h5 class="pt-2">Cosmic Chemistry, Chapter 8</h5>
                            <p class="mb-1">
                                The analogy of letters and words is exactly right since the crucial feature that characterizes proteins is that the amino acids which comprise them <i>must be in exactly the right places in the chain</i>. For proteins are not made simply by mixing the right amino acids together in the correct proportions, as we might mix an inorganic acid with an alkali to produce a salt and water. Proteins are immensely specialized and intricate constructions of long chains of amino acid molecules in a specific linear order. The amino acids may be thought of as the twenty 'letters' of a chemical 'alphabet'. Then the protein is an incredibly long 'word' in that alphabet. In this word every amino acid 'letter' must be in the right place. That is, the order in which the amino acids are arranged in the chain is the vital thing, not simply the fact that they are there - just as the letters in a word, or the keystrokes in a computer program, must be in the correct order for the word to mean what it should mean, or for the program to work. A single letter in the wrong place, and the word could become another word or complete nonsense; a single incorrect keystroke in a computer program, and it will probably cease to function. <br> <br>
                                
                                The point of this argument is made very clear from elementary probability calculations. The probability of getting the correct amino acid at a specific site in the protein is 1/20. Thus the probability of getting 100 amino acids in the correct order would be (1/20)<sup>100</sup>, which is about 1 in 10<sup>130</sup>, and therefore unimaginably small.... 

                                But that is only the start, and a very modest start at that. For these calculations concern only a single protein. Yet life as we know it requires hundreds of thousands of proteins, and it has been calculated that the odds against producing these by chance is more than 10<sup>40,000</sup> to 1. Sir Fred Hoyle famously compared these odds against the spontaneous formation of life with the chance of a tornado sweeping through a junkyard and producing a Boeing 747 jet aircraft.
                            </p>
                        </blockquote> -->
                        <!-- Dr. Stephen Meyer -->
                        <!-- <blockquote>
                            <h5 class="pt-2">Return of the God Hypothesis, Chapter 9</h5>
                            <p class="mb-1">
                                In my book <i>Signature in the Cell</i>, I perform updated calculations of the probability of the origin of even a single functional protein or corresponding functional gene (the section of a DNA molecule that directs the synthesis of a particular protein) by chance alone. My calculations are based upon recent experiments in molecular biology establishing the extreme rarity of functional proteins in relation to the total number of possible arrangements of amino acids corresponding to a protein of a given length. Taking that and several other relevant independent factors into account, I show that the probability of producing even a single functional protein of modest length (150 amino acids) by chance alone in a prebiotic environment stands at no better than a "vanishingly small" 1 chance in 10<sup>164</sup>, an inconceivably small probability. To put this number in perspective, recall that physicists estimate that there are only 10<sup>80</sup> elementary particles in the entire universe. <br> <br>
                                
                                In <i>Signature</i>, I also show that the probability of generating a single functional protein is extremely small in relation to all the opportunities for that event to occur since the beginning of time (what are called the "probabilistic resources" of the universe). Even if every event in the entire history of the universe (where an event is defined minimally as an interaction between elementary particles) were devoted to producing combinations of amino acids of a given length (an extravagantly generous assumption), the number of combinations thus produced would still represent only a tiny portion - less than one out of a trillion trillion - of the total number of possible amino-acid combinations corresponding to a functional protein—any functional protein—of that given length. <br> <br>
                                
                                In short, it is extremely implausible to think that even a single protein would have arisen by chance on the early earth even taking into account the "probabilistic resources" of the entire universe over its 13.8-billion-year history. And a single protein, keep in mind, does not a living cell, with its many hundreds of specialized proteins, make.
                            </p>
                        </blockquote> -->
                        <!-- <blockquote>
                            <h5 class="pt-2">Signature in the Cell, Chapter 9</h5>
                            <p class="mb-1">
                                Axe's improved estimate of how rare functional proteins are within "sequence space" has now made it possible to calculate the probability that a 150-amino-acid compound assembled by random interactions in a prebiotic soup would be a functional protein. This calculation can be made by multiplying the three independent probabilities by one another: the probability of incorporating only peptide bonds (1 in 10<sup>45</sup>), the probability of incorporating only left-handed amino acids (1 in 10<sup>45</sup>), and the probability of achieving correct amino-acid sequencing (using Axe's 1 in 10<sup>74</sup> estimate). Making that calculation (multiplying the separate probabilities by adding their exponents: 10<sup>45 + 45 + 74</sup>) gives a dramatic answer. The odds of getting even one functional protein of modest length (150 amino acids) by chance from a prebiotic soup is no better than 1 chance in 10<sup>164</sup>.... <br> <br>

                                And the problem is even worse than this for at least two reasons. First, Axe's experiments calculated the odds of finding a relatively short protein by chance alone. More typical proteins have hundreds of amino acids, and in many cases, their function requires close association with other protein chains. For example, the typical RNA polymerase—the large molecular machine the cell uses to copy genetic information during transcription (discussed in Chapter 5)—has over 3,000 functionally specified amino acids. The probability of producing such a protein and many other necessary proteins by chance would be far smaller than the odds of producing a 150-amino-acid protein. <br> <br>
                                
                                Second, as discussed, a minimally complex cell would require many more proteins than just one. Taking this into account only causes the improbability of generating the necessary proteins by chance—or the genetic information to produce them—to balloon beyond comprehension. In 1983 distinguished British cosmologist Sir Fred Hoyle calculated the odds of producing the proteins necessary to service a simple one-celled organism by chance at 1 in 10<sup>40,000</sup>. At that time scientists could have questioned his figure. Scientists knew how long proteins were and roughly how many protein types there were in simple cells. But since the amount of functionally specified information in each protein had not yet been measured, probability calculations like Hoyle's required some guesswork.
                            </p>
                        </blockquote> -->
                        <!-- <blockquote>
                            <h5 class="pt-2">Signature in the Cell, Chapter 10</h5>
                            <p class="mb-1">
                                Dembski's calculation was elegantly simple and yet made a powerful point. He noted that there were about 10<sup>80</sup> elementary particles in the observable universe. (Because there is an upper limit on the speed of light, only those parts of the universe that are observable to us can affect events on earth. Thus, the observable universe is the only part of the universe with probabilistic resources relevant to explaining events on earth.) Dembski also noted that there had been roughly 10<sup>16</sup> seconds since the big bang. (A few more have transpired since he made the calculation, but not enough to make a difference!).... <br> <br>
                                
                                Dembski was able to calculate this number by simply multiplying the three relevant factors together: the number of elementary particles (10<sup>80</sup>) times the number of seconds since the big bang (10<sup>16</sup>) times the number of possible interactions per second (10<sup>43</sup>). His calculation fixed the total number of events that could have taken place in the observable universe since the origin of the universe at 10<sup>139</sup>. This then provided a measure of the probabilistic resources of the entire observable universe.
                            </p>
                        </blockquote> -->



                    </div>
                </div>
            </div>
        </div>
    </div>

    <footer></footer>


    <!-- Optional JavaScript -->
    <!-- Bootstrap JS -->
    <script src="../../../style/bootstrap/js/bootstrap.bundle.min.js"></script>

    <script src="https://www.biblegateway.com/public/link-to-us/tooltips/bglinks.js" type="text/javascript"></script>
    <script type="text/javascript">
        BGLinks.version = "KJV";
        BGLinks.linkVerses();
    </script>
</body>

</html>